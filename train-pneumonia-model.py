# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16zQNPMigkz66i2Oz_VTUVu8iFU1EV-Wc
"""

import numpy as np
import pandas as pd
import cv2
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay
import matplotlib.pyplot as plt
import seaborn as sns
import gc
import os

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Memory optimization callback
class MemoryCleanup(Callback):
    def on_epoch_end(self, epoch, logs=None):
        gc.collect()
        tf.keras.backend.clear_session()
# Load dataset
print("Loading dataset...")
pn = np.load('pneumoniamnist.npz')
X_test = pn['test_images']
Y_test = pn['test_labels']
X_val = pn['val_images']
Y_val = pn['val_labels']
X_train = pn['train_images']
Y_train = pn['train_labels']

# Print dataset shapes
print("\nDataset Shapes:")
print(f"Train: {X_train.shape}, {Y_train.shape}")
print(f"Validation: {X_val.shape}, {Y_val.shape}")
print(f"Test: {X_test.shape}, {Y_test.shape}")

# Print class distribution
print("\nClass Distribution:")
print(f"Train: Normal {np.sum(Y_train==0)} | Pneumonia {np.sum(Y_train==1)}")
print(f"Validation: Normal {np.sum(Y_val==0)} | Pneumonia {np.sum(Y_val==1)}")
print(f"Test: Normal {np.sum(Y_test==0)} | Pneumonia {np.sum(Y_test==1)}")

# Smaller image size to save RAM
IMG_SIZE = (128, 128)
BATCH_SIZE = 4  # Reduced batch size
# On-the-fly preprocessing generator
def preprocess_image(img):
    img = cv2.resize(img, IMG_SIZE)
    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    return img / 255.0

class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, images, labels, batch_size, augment=False):
        self.images = images
        self.labels = labels
        self.batch_size = batch_size
        self.augment = augment
        self.indices = np.arange(len(images))
        self.augmenter = tf.keras.preprocessing.image.ImageDataGenerator(
            horizontal_flip=True,
            rotation_range=10,
            zoom_range=0.1
        ) if augment else None

    def __len__(self):
        return int(np.ceil(len(self.images) / self.batch_size))

    def __getitem__(self, index):
        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]
        batch_images = []
        batch_labels = self.labels[batch_indices]

        for i in batch_indices:
            img = preprocess_image(self.images[i])
            batch_images.append(img)

        batch_images = np.array(batch_images)

        if self.augment and self.augmenter:
            batch_images = next(self.augmenter.flow(
                batch_images,
                batch_size=self.batch_size,
                shuffle=False
            ))

        return batch_images, to_categorical(batch_labels, 2)

    def on_epoch_end(self):
        np.random.shuffle(self.indices)

# Convert labels to categorical
y_val_cat = to_categorical(Y_val, 2)
y_test_cat = to_categorical(Y_test, 2)

# Compute class weights
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(Y_train),
    y=Y_train.flatten()
)
class_weights_dict = dict(enumerate(class_weights))
print(f"\nClass weights: {class_weights_dict}")

# Clear RAM before building model
gc.collect()
tf.keras.backend.clear_session()

# Create generators
print("\nCreating data generators...")
train_generator = DataGenerator(X_train, Y_train, BATCH_SIZE, augment=True)
val_generator = DataGenerator(X_val, Y_val, BATCH_SIZE)

# Load InceptionV3 base model with RAM-friendly approach
print("\nBuilding InceptionV3 model...")
# Load model without including top to save memory
base_model = InceptionV3(
    weights='imagenet',
    include_top=False,
    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)
)

# Freeze base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add custom head with regularization
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.7)(x)
x = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(x)  # Reduced units
predictions = Dense(2, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# Compile model with additional metrics
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=[
        'accuracy',
        tf.keras.metrics.AUC(name='auc'),
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall')
    ]
)

# Callbacks
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=2,
    min_lr=1e-7,
    verbose=1
)

memory_cleanup = MemoryCleanup()

# Train model with generators
print("\nTraining model...")
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,  # Reduced epochs
    class_weight=class_weights_dict,
    callbacks=[early_stop, lr_scheduler, memory_cleanup]
)

# Plot training curves (simplified to save memory)
plt.figure(figsize=(12, 8))

# Accuracy
plt.subplot(2, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss
plt.subplot(2, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# AUC
plt.subplot(2, 2, 3)
plt.plot(history.history['auc'], label='Train AUC')
plt.plot(history.history['val_auc'], label='Val AUC')
plt.title('AUC Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('AUC')
plt.legend()

# Recall
plt.subplot(2, 2, 4)
plt.plot(history.history['recall'], label='Train Recall')
plt.plot(history.history['val_recall'], label='Val Recall')
plt.title('Recall Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Recall')
plt.legend()

plt.tight_layout()
plt.savefig('training_metrics.png')
plt.close()  # Close plot to save memory

# Clean up before evaluation
gc.collect()
tf.keras.backend.clear_session()

# Evaluate on test set in batches
print("\nEvaluating on test set...")
test_generator = DataGenerator(X_test, Y_test, BATCH_SIZE)
test_metrics = model.evaluate(test_generator)
print("\nTest Metrics:")
print(f"Loss: {test_metrics[0]:.4f}")
print(f"Accuracy: {test_metrics[1]:.4f}")
print(f"AUC: {test_metrics[2]:.4f}")
print(f"Precision: {test_metrics[3]:.4f}")
print(f"Recall: {test_metrics[4]:.4f}")

# Predict on test set in batches
y_pred_prob = []
y_pred_classes = []
y_true = []

for i in range(len(test_generator)):
    x_batch, y_batch = test_generator[i]
    batch_pred = model.predict(x_batch, verbose=0)
    y_pred_prob.extend(batch_pred)
    y_pred_classes.extend(np.argmax(batch_pred, axis=1))
    y_true.extend(np.argmax(y_batch, axis=1))

y_pred_prob = np.array(y_pred_prob)
y_pred_classes = np.array(y_pred_classes)
y_true = np.array(y_true)

# Confusion matrix (counts)
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Normal', 'Pneumonia'],
            yticklabels=['Normal', 'Pneumonia'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix (Counts)')
plt.savefig('confusion_matrix_counts.png')
plt.close()

# ROC curve
plt.figure(figsize=(8, 6))
RocCurveDisplay.from_predictions(
    y_true,
    y_pred_prob[:, 1],
    name="Pneumonia Classification",
    color="darkorange"
)
plt.plot([0, 1], [0, 1], 'k--', label="Random Guessing")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.savefig('roc_curve.png')
plt.close()

# Classification report
print("\nClassification Report:")
print(classification_report(y_true, y_pred_classes,
                            target_names=['Normal', 'Pneumonia']))

# Calculate AUC
auc = roc_auc_score(y_true, y_pred_prob[:, 1])
print(f"AUC: {auc:.4f}")

# Save model and predictions
print("\nSaving model and predictions...")
model.save('inceptionv3_pneumonia_classifier.h5', save_format='h5')
df = pd.DataFrame({
    'True_Label': y_true,
    'Predicted_Label': y_pred_classes,
    'Pneumonia_Probability': y_pred_prob[:, 1]
})
df.to_csv('pneumonia_predictions.csv', index=False)
# Final cleanup
del model, base_model, train_generator, val_generator, test_generator
gc.collect()
tf.keras.backend.clear_session()

print("\nTraining and evaluation complete!")